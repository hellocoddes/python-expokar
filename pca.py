# -*- coding: utf-8 -*-
"""9

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JJPI5_VtxqMlRqu9eXHSwu_Gepa6YZyY
"""

import numpy as np
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt

# Example dataset (4D to 2D)
X = np.array([
    [2, 8, 4, 6],
    [3, 6, 2, 8],
    [4, 8, 6, 2],
    [6, 4, 8, 2],
    [8, 6, 2, 4]
])

# Apply PCA to reduce to 2 components
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X)

print("PCA Components:\n", pca.components_)
print("Transformed Data:\n", X_pca)

# Plot
plt.scatter(X_pca[:,0], X_pca[:,1])
plt.title("PCA Result (2D Projection)")
plt.xlabel("PC1")
plt.ylabel("PC2")
plt.show()



import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt

# Example data
X = np.random.rand(100, 10)

# 1. Standardize
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# 2. PCA with explained variance threshold (e.g., 95%)
pca = PCA(n_components=0.95, svd_solver='full')
X_pca = pca.fit_transform(X_scaled)

print(f"Original shape: {X.shape}, Reduced shape: {X_pca.shape}")
print("Explained variance ratio:", pca.explained_variance_ratio_)

# 3. Visualize
plt.bar(range(1, len(pca.explained_variance_ratio_)+1), pca.explained_variance_ratio_)
plt.xlabel('Principal Component')
plt.ylabel('Variance Explained')
plt.title('PCA Explained Variance')
plt.show()

