# -*- coding: utf-8 -*-
"""Untitled

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OxDYIrKTyn0hD--tHy3ghNxLVgKaQ9CA
"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import make_regression
from sklearn.metrics import mean_squared_error, r2_score

class LinearRegression:
    """Base class for linear regression models."""
    
    def __init__(self):
        self.weights = None
        self.bias = None
        
    def fit(self, X, y):
        # Add bias term to X
        X_b = np.c_[np.ones((X.shape[0], 1)), X]
        # Normal equation: theta = (X^T X)^(-1) X^T y
        theta = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y)
        self.bias = theta[0]
        self.weights = theta[1:]
        return self
        
    def predict(self, X):
        return np.dot(X, self.weights) + self.bias

class Ridge(LinearRegression):
    """Ridge regression (L2 regularization)"""
    
    def __init__(self, alpha=1.0):
        super().__init__()
        self.alpha = alpha
        
    def fit(self, X, y):
        # Add bias term to X
        X_b = np.c_[np.ones((X.shape[0], 1)), X]
        # Ridge solution: theta = (X^T X + alpha I)^(-1) X^T y
        I = np.eye(X_b.shape[1])
        I[0, 0] = 0  # Don't regularize bias term
        theta = np.linalg.inv(X_b.T.dot(X_b) + self.alpha * I).dot(X_b.T).dot(y)
        self.bias = theta[0]
        self.weights = theta[1:]
        return self

class Lasso:
    """Lasso regression (L1 regularization) using coordinate descent"""
    
    def __init__(self, alpha=1.0, max_iter=1000, tol=1e-4):
        self.alpha = alpha
        self.max_iter = max_iter
        self.tol = tol
        self.weights = None
        self.bias = None
        
    def _soft_threshold(self, x, lambda_):
        """Soft-thresholding operator"""
        if x > lambda_:
            return x - lambda_
        elif x < -lambda_:
            return x + lambda_
        return 0
        
    def fit(self, X, y):
        n_samples, n_features = X.shape
        
        # Initialize parameters
        self.weights = np.zeros(n_features)
        self.bias = np.mean(y)
        y_centered = y - self.bias
        
        # Normalize features
        X_norm = np.sqrt(np.sum(X ** 2, axis=0))
        X_normalized = X / X_norm[np.newaxis, :]
        
        # Coordinate descent
        for _ in range(self.max_iter):
            weights_old = self.weights.copy()
            
            # Update each coordinate
            for j in range(n_features):
                r = y_centered - np.dot(X_normalized, self.weights)
                r += X_normalized[:, j] * self.weights[j]
                self.weights[j] = self._soft_threshold(
                    np.dot(X_normalized[:, j], r),
                    self.alpha
                )
            
            # Check convergence
            if np.sum(np.abs(self.weights - weights_old)) < self.tol:
                break
                
        # Rescale weights
        self.weights = self.weights / X_norm
        return self
        
    def predict(self, X):
        return np.dot(X, self.weights) + self.bias

# Generate synthetic regression data
X, y = make_regression(n_samples=150, n_features=5, noise=20, random_state=42)

# Split into train and test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Ridge Regression
ridge = Ridge(alpha=1.0)
ridge.fit(X_train, y_train)
y_pred_ridge = ridge.predict(X_test)

# Lasso Regression
lasso = Lasso(alpha=1.0)
lasso.fit(X_train, y_train)
y_pred_lasso = lasso.predict(X_test)

# Evaluate performance
ridge_mse = mean_squared_error(y_test, y_pred_ridge)
ridge_r2 = r2_score(y_test, y_pred_ridge)

lasso_mse = mean_squared_error(y_test, y_pred_lasso)
lasso_r2 = r2_score(y_test, y_pred_lasso)

print(f"Ridge Regression MSE: {ridge_mse:.2f}, R2: {ridge_r2:.2f}")
print(f"Lasso Regression MSE: {lasso_mse:.2f}, R2: {lasso_r2:.2f}")

# Plot true vs predicted values
plt.figure(figsize=(10,5))
plt.plot(y_test, label='True Values', marker='o')
plt.plot(y_pred_ridge, label='Ridge Predictions', marker='x')
plt.plot(y_pred_lasso, label='Lasso Predictions', marker='^')
plt.legend()
plt.title('Ridge vs Lasso Regression Predictions')
plt.xlabel('Sample index')
plt.ylabel('Target value')
plt.show()

